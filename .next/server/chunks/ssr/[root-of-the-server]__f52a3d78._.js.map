{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 215, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/src/ai/genkit.ts"],"sourcesContent":["import {genkit} from 'genkit';\r\nimport {googleAI} from '@genkit-ai/googleai';\r\n\r\nexport const ai = genkit({\r\n  plugins: [googleAI()],\r\n  model: 'googleai/gemini-2.0-flash',\r\n});\r\n"],"names":[],"mappings":";;;AAAA;AAAA;AACA;AAAA;;;AAEO,MAAM,KAAK,CAAA,GAAA,uIAAA,CAAA,SAAM,AAAD,EAAE;IACvB,SAAS;QAAC,CAAA,GAAA,2KAAA,CAAA,WAAQ,AAAD;KAAI;IACrB,OAAO;AACT","debugId":null}},
    {"offset": {"line": 236, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/src/ai/flows/translate-text.ts"],"sourcesContent":["\r\n'use server';\r\n\r\n/**\r\n * @fileOverview A text translation flow using Genkit and Google AI.\r\n * \r\n * - translateText - Translates text to a specified target language.\r\n * - TranslateTextInput - The input type for the translateText function.\r\n * - TranslateTextOutput - The return type for the translateText function.\r\n */\r\n\r\nimport {ai} from '@/ai/genkit';\r\nimport {z} from 'genkit';\r\n\r\nconst TranslateTextInputSchema = z.object({\r\n  text: z.string().describe('The text to be translated. This may contain multiple lines separated by \"\\\\n---\\\\n\".'),\r\n  targetLanguage: z.string().describe('The target language for translation (e.g., \"hi\", \"ta\").'),\r\n});\r\nexport type TranslateTextInput = z.infer<typeof TranslateTextInputSchema>;\r\n\r\nconst TranslateTextOutputSchema = z.object({\r\n  translatedText: z.string().describe('The translated text, preserving the \"\\\\n---\\\\n\" separators.'),\r\n});\r\nexport type TranslateTextOutput = z.infer<typeof TranslateTextOutputSchema>;\r\n\r\nexport async function translateText(input: TranslateTextInput): Promise<TranslateTextOutput> {\r\n  return translateTextFlow(input);\r\n}\r\n\r\nconst translateTextFlow = ai.defineFlow(\r\n  {\r\n    name: 'translateTextFlow',\r\n    inputSchema: TranslateTextInputSchema,\r\n    outputSchema: TranslateTextOutputSchema,\r\n  },\r\n  async ({ text, targetLanguage }) => {\r\n    // Handle cases where the text might be empty or just separators\r\n    if (!text.trim() || text.trim() === '---') {\r\n      return { translatedText: text };\r\n    }\r\n\r\n    const { text: translatedText } = await ai.generate({\r\n      model: 'googleai/gemini-2.0-flash',\r\n      prompt: `Translate the following text to the language with code '${targetLanguage}'. The text may contain multiple distinct entries separated by \"\\\\n---\\\\n\". Maintain this separator in your output. Return only the translated text, preserving the separators exactly as they appear in the input.\\n\\nText to translate: \"${text}\"`,\r\n    });\r\n    \r\n    return {\r\n      translatedText,\r\n    };\r\n  }\r\n);\r\n"],"names":[],"mappings":";;;;;AAGA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,2BAA2B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACxC,MAAM,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC1B,gBAAgB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AACtC;AAGA,MAAM,4BAA4B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACzC,gBAAgB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AACtC;AAGO,eAAe,cAAc,KAAyB;IAC3D,OAAO,kBAAkB;AAC3B;AAEA,MAAM,oBAAoB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACrC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO,EAAE,IAAI,EAAE,cAAc,EAAE;IAC7B,gEAAgE;IAChE,IAAI,CAAC,KAAK,IAAI,MAAM,KAAK,IAAI,OAAO,OAAO;QACzC,OAAO;YAAE,gBAAgB;QAAK;IAChC;IAEA,MAAM,EAAE,MAAM,cAAc,EAAE,GAAG,MAAM,mHAAA,CAAA,KAAE,CAAC,QAAQ,CAAC;QACjD,OAAO;QACP,QAAQ,CAAC,wDAAwD,EAAE,eAAe,2OAA2O,EAAE,KAAK,CAAC,CAAC;IACxU;IAEA,OAAO;QACL;IACF;AACF;;;IAxBoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 295, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/src/ai/flows/crop-diagnosis.ts"],"sourcesContent":["'use server';\r\n/**\r\n * @fileOverview A crop disease diagnosis AI agent.\r\n *\r\n * - diagnoseCrop - A function that handles the crop diagnosis process.\r\n * - DiagnoseCropInput - The input type for the diagnoseCrop function.\r\n * - DiagnoseCropOutput - The return type for the diagnoseCrop function.\r\n */\r\n\r\nimport {ai} from '@/ai/genkit';\r\nimport {z} from 'genkit';\r\n\r\nconst DiagnoseCropInputSchema = z.object({\r\n  photoDataUri: z\r\n    .string()\r\n    .describe(\r\n      \"A photo of the crop, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'.\"\r\n    ),\r\n  description: z.string().optional().describe('An optional description of the crop issue.'),\r\n});\r\nexport type DiagnoseCropInput = z.infer<typeof DiagnoseCropInputSchema>;\r\n\r\nconst DiagnoseCropOutputSchema = z.object({\r\n  diseaseName: z.string().describe('The name of the identified disease.'),\r\n  possibleCauses: z.string().describe('Possible causes of the disease.'),\r\n  recommendedRemedies: z.string().describe('AI-recommended remedies for the disease.'),\r\n  preventiveMeasures: z.string().describe('Preventive measures to avoid the disease in the future.'),\r\n});\r\nexport type DiagnoseCropOutput = z.infer<typeof DiagnoseCropOutputSchema>;\r\n\r\nexport async function diagnoseCrop(input: DiagnoseCropInput): Promise<DiagnoseCropOutput> {\r\n  return diagnoseCropFlow(input);\r\n}\r\n\r\nconst prompt = ai.definePrompt({\r\n  name: 'diagnoseCropPrompt',\r\n  input: {schema: DiagnoseCropInputSchema},\r\n  output: {schema: DiagnoseCropOutputSchema},\r\n  prompt: `You are an expert in diagnosing crop diseases. Analyze the provided information to identify the disease, its possible causes, recommend remedies, and suggest preventive measures.\r\n\r\n{{#if description}}Description: {{{description}}}{{/if}}\r\nPhoto: {{media url=photoDataUri}}\r\n\r\nIf no description is provided, rely solely on the image for your analysis.`,\r\n});\r\n\r\nconst diagnoseCropFlow = ai.defineFlow(\r\n  {\r\n    name: 'diagnoseCropFlow',\r\n    inputSchema: DiagnoseCropInputSchema,\r\n    outputSchema: DiagnoseCropOutputSchema,\r\n  },\r\n  async input => {\r\n    const {output} = await prompt(input);\r\n    return output!;\r\n  }\r\n);\r\n"],"names":[],"mappings":";;;;;AACA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,0BAA0B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACvC,cAAc,uIAAA,CAAA,IAAC,CACZ,MAAM,GACN,QAAQ,CACP;IAEJ,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC9C;AAGA,MAAM,2BAA2B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACxC,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACjC,gBAAgB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACpC,qBAAqB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACzC,oBAAoB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC1C;AAGO,eAAe,aAAa,KAAwB;IACzD,OAAO,iBAAiB;AAC1B;AAEA,MAAM,SAAS,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;IAC7B,MAAM;IACN,OAAO;QAAC,QAAQ;IAAuB;IACvC,QAAQ;QAAC,QAAQ;IAAwB;IACzC,QAAQ,CAAC;;;;;0EAK+D,CAAC;AAC3E;AAEA,MAAM,mBAAmB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACpC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAM;IACJ,MAAM,EAAC,MAAM,EAAC,GAAG,MAAM,OAAO;IAC9B,OAAO;AACT;;;IAzBoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 377, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/src/ai/flows/text-to-speech.ts"],"sourcesContent":["\r\n'use server';\r\n\r\n/**\r\n * @fileOverview A text-to-speech (TTS) flow using Genkit and Google AI.\r\n * \r\n * - textToSpeech - Converts a string of text into speech audio.\r\n * - TextToSpeechInput - The input type for the textToSpeech function.\r\n * - TextToSpeechOutput - The return type for the textToSpeech function.\r\n */\r\n\r\nimport {ai} from '@/ai/genkit';\r\nimport {googleAI} from '@genkit-ai/googleai';\r\nimport {z} from 'genkit';\r\nimport wav from 'wav';\r\nimport { translateText } from './translate-text';\r\n\r\nconst TextToSpeechInputSchema = z.object({\r\n  text: z.string().describe('The text to be converted to speech.'),\r\n  language: z.string().optional().describe('The language to use for the speech, e.g., \"en\", \"ta\".'),\r\n});\r\nexport type TextToSpeechInput = z.infer<typeof TextToSpeechInputSchema>;\r\n\r\nconst TextToSpeechOutputSchema = z.object({\r\n  audioDataUri: z.string().describe(\"The generated audio as a data URI. Expected format: 'data:audio/wav;base64,<encoded_data>'.\"),\r\n});\r\nexport type TextToSpeechOutput = z.infer<typeof TextToSpeechOutputSchema>;\r\n\r\n\r\nexport async function textToSpeech(input: TextToSpeechInput): Promise<TextToSpeechOutput> {\r\n  return textToSpeechFlow(input);\r\n}\r\n\r\nconst getVoiceForLanguage = (language?: string) => {\r\n    switch (language) {\r\n      case 'ta':\r\n        return 'Achernar';\r\n      case 'hi':\r\n        return 'Achird';\r\n      case 'te':\r\n        return 'Alnilam';\r\n      case 'kn':\r\n        return 'Erinome';\r\n      case 'ml':\r\n        return 'Gacrux';\r\n      case 'en':\r\n      default:\r\n        return 'Algenib';\r\n    }\r\n}\r\n\r\nconst textToSpeechFlow = ai.defineFlow(\r\n  {\r\n    name: 'textToSpeechFlow',\r\n    inputSchema: TextToSpeechInputSchema,\r\n    outputSchema: TextToSpeechOutputSchema,\r\n  },\r\n  async ({ text, language }) => {\r\n    const voiceName = getVoiceForLanguage(language);\r\n    \r\n    let textToSpeak = text;\r\n    if (language && language !== 'en') {\r\n      const translationResponse = await translateText({ text, targetLanguage: language });\r\n      textToSpeak = translationResponse.translatedText;\r\n    }\r\n\r\n\r\n    const { media } = await ai.generate({\r\n      model: googleAI.model('gemini-2.5-flash-preview-tts'),\r\n      config: {\r\n        responseModalities: ['AUDIO'],\r\n        speechConfig: {\r\n          voiceConfig: {\r\n            prebuiltVoiceConfig: { voiceName },\r\n          },\r\n        },\r\n      },\r\n      prompt: textToSpeak,\r\n    });\r\n    \r\n    if (!media) {\r\n      throw new Error('No audio media was generated.');\r\n    }\r\n\r\n    const audioBuffer = Buffer.from(\r\n      media.url.substring(media.url.indexOf(',') + 1),\r\n      'base64'\r\n    );\r\n\r\n    const wavData = await toWav(audioBuffer);\r\n    \r\n    return {\r\n      audioDataUri: 'data:audio/wav;base64,' + wavData,\r\n    };\r\n  }\r\n);\r\n\r\n\r\nasync function toWav(\r\n  pcmData: Buffer,\r\n  channels = 1,\r\n  rate = 24000,\r\n  sampleWidth = 2\r\n): Promise<string> {\r\n  return new Promise((resolve, reject) => {\r\n    const writer = new wav.Writer({\r\n      channels,\r\n      sampleRate: rate,\r\n      bitDepth: sampleWidth * 8,\r\n    });\r\n\r\n    const bufs: Buffer[] = [];\r\n    writer.on('error', reject);\r\n    writer.on('data', (chunk) => {\r\n      bufs.push(chunk);\r\n    });\r\n    writer.on('end', () => {\r\n      resolve(Buffer.concat(bufs).toString('base64'));\r\n    });\r\n\r\n    writer.write(pcmData);\r\n    writer.end();\r\n  });\r\n}\r\n"],"names":[],"mappings":";;;;;AAGA;;;;;;CAMC,GAED;AACA;AAAA;AACA;AAAA;AACA;AACA;;;;;;;;;AAEA,MAAM,0BAA0B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACvC,MAAM,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC1B,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC3C;AAGA,MAAM,2BAA2B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACxC,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AACpC;AAIO,eAAe,aAAa,KAAwB;IACzD,OAAO,iBAAiB;AAC1B;AAEA,MAAM,sBAAsB,CAAC;IACzB,OAAQ;QACN,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;QACL;YACE,OAAO;IACX;AACJ;AAEA,MAAM,mBAAmB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACpC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO,EAAE,IAAI,EAAE,QAAQ,EAAE;IACvB,MAAM,YAAY,oBAAoB;IAEtC,IAAI,cAAc;IAClB,IAAI,YAAY,aAAa,MAAM;QACjC,MAAM,sBAAsB,MAAM,CAAA,GAAA,uIAAA,CAAA,gBAAa,AAAD,EAAE;YAAE;YAAM,gBAAgB;QAAS;QACjF,cAAc,oBAAoB,cAAc;IAClD;IAGA,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM,mHAAA,CAAA,KAAE,CAAC,QAAQ,CAAC;QAClC,OAAO,2KAAA,CAAA,WAAQ,CAAC,KAAK,CAAC;QACtB,QAAQ;YACN,oBAAoB;gBAAC;aAAQ;YAC7B,cAAc;gBACZ,aAAa;oBACX,qBAAqB;wBAAE;oBAAU;gBACnC;YACF;QACF;QACA,QAAQ;IACV;IAEA,IAAI,CAAC,OAAO;QACV,MAAM,IAAI,MAAM;IAClB;IAEA,MAAM,cAAc,OAAO,IAAI,CAC7B,MAAM,GAAG,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,OAAO,CAAC,OAAO,IAC7C;IAGF,MAAM,UAAU,MAAM,MAAM;IAE5B,OAAO;QACL,cAAc,2BAA2B;IAC3C;AACF;AAIF,eAAe,MACb,OAAe,EACf,WAAW,CAAC,EACZ,OAAO,KAAK,EACZ,cAAc,CAAC;IAEf,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,MAAM,SAAS,IAAI,4HAAA,CAAA,UAAG,CAAC,MAAM,CAAC;YAC5B;YACA,YAAY;YACZ,UAAU,cAAc;QAC1B;QAEA,MAAM,OAAiB,EAAE;QACzB,OAAO,EAAE,CAAC,SAAS;QACnB,OAAO,EAAE,CAAC,QAAQ,CAAC;YACjB,KAAK,IAAI,CAAC;QACZ;QACA,OAAO,EAAE,CAAC,OAAO;YACf,QAAQ,OAAO,MAAM,CAAC,MAAM,QAAQ,CAAC;QACvC;QAEA,OAAO,KAAK,CAAC;QACb,OAAO,GAAG;IACZ;AACF;;;IA9FsB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 499, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/src/ai/flows/speech-to-text.ts"],"sourcesContent":["'use server';\r\n\r\n/**\r\n * @fileOverview A speech-to-text (STT) flow using Genkit and Google AI.\r\n *\r\n * - speechToText - Converts speech audio into text.\r\n * - SpeechToTextInput - The input type for the speechToText function.\r\n * - SpeechToTextOutput - The return type for the speechToText function.\r\n */\r\n\r\nimport {ai} from '@/ai/genkit';\r\nimport {z} from 'genkit';\r\n\r\nconst SpeechToTextInputSchema = z.object({\r\n  audioDataUri: z\r\n    .string()\r\n    .describe(\r\n      \"The speech audio as a data URI. Expected format: 'data:audio/wav;base64,<encoded_data>'.\"\r\n    ),\r\n  language: z.string().optional().describe('The BCP-47 language code for transcription (e.g., \"en-US\", \"hi-IN\").'),\r\n});\r\nexport type SpeechToTextInput = z.infer<typeof SpeechToTextInputSchema>;\r\n\r\nconst SpeechToTextOutputSchema = z.object({\r\n  text: z.string().describe('The transcribed text.'),\r\n});\r\nexport type SpeechToTextOutput = z.infer<typeof SpeechToTextOutputSchema>;\r\n\r\nexport async function speechToText(input: SpeechToTextInput): Promise<SpeechToTextOutput> {\r\n  return speechToTextFlow(input);\r\n}\r\n\r\nconst speechToTextFlow = ai.defineFlow(\r\n  {\r\n    name: 'speechToTextFlow',\r\n    inputSchema: SpeechToTextInputSchema,\r\n    outputSchema: SpeechToTextOutputSchema,\r\n  },\r\n  async ({ audioDataUri, language }) => {\r\n    const languagePrompt = language ? ` The user is speaking in ${language}. Transcribe it accurately in that language.` : '';\r\n    \r\n    const { text } = await ai.generate({\r\n      model: 'googleai/gemini-2.0-flash',\r\n      prompt: [{ media: { url: audioDataUri } }, {text: `Transcribe the following audio accurately. The audio contains a description of crop symptoms for agricultural diagnosis.${languagePrompt}`}],\r\n    });\r\n\r\n    return {\r\n      text,\r\n    };\r\n  }\r\n);\r\n"],"names":[],"mappings":";;;;;AAEA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,0BAA0B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACvC,cAAc,uIAAA,CAAA,IAAC,CACZ,MAAM,GACN,QAAQ,CACP;IAEJ,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC3C;AAGA,MAAM,2BAA2B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACxC,MAAM,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC5B;AAGO,eAAe,aAAa,KAAwB;IACzD,OAAO,iBAAiB;AAC1B;AAEA,MAAM,mBAAmB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACpC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO,EAAE,YAAY,EAAE,QAAQ,EAAE;IAC/B,MAAM,iBAAiB,WAAW,CAAC,yBAAyB,EAAE,SAAS,4CAA4C,CAAC,GAAG;IAEvH,MAAM,EAAE,IAAI,EAAE,GAAG,MAAM,mHAAA,CAAA,KAAE,CAAC,QAAQ,CAAC;QACjC,OAAO;QACP,QAAQ;YAAC;gBAAE,OAAO;oBAAE,KAAK;gBAAa;YAAE;YAAG;gBAAC,MAAM,CAAC,wHAAwH,EAAE,gBAAgB;YAAA;SAAE;IACjM;IAEA,OAAO;QACL;IACF;AACF;;;IArBoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 562, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/.next-internal/server/app/crop-diagnosis/page/actions.js%20%28server%20actions%20loader%29"],"sourcesContent":["export {translateText as '402578704a0068c0448430b72144adf3acc23f7769'} from 'ACTIONS_MODULE0'\nexport {diagnoseCrop as '406e1de68e2f9ef3e4e2c9b36da445e597bf8558ad'} from 'ACTIONS_MODULE1'\nexport {textToSpeech as '40e37f7155e0bdf442d0c48b77ee9f28f61a70f186'} from 'ACTIONS_MODULE2'\nexport {speechToText as '4032f1b03923a55598788ff50d25ed88cf179615f1'} from 'ACTIONS_MODULE3'\n"],"names":[],"mappings":";AAAA;AACA;AACA;AACA","debugId":null}},
    {"offset": {"line": 626, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/src/app/crop-diagnosis/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/crop-diagnosis/page.tsx <module evaluation> from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/crop-diagnosis/page.tsx <module evaluation>\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAmS,GAChU,iEACA","debugId":null}},
    {"offset": {"line": 640, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Dhivyaa/AgriVision/src/app/crop-diagnosis/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/crop-diagnosis/page.tsx from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/crop-diagnosis/page.tsx\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAA+Q,GAC5S,6CACA","debugId":null}},
    {"offset": {"line": 654, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}}]
}